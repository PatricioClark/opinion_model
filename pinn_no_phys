""" PINN implementation of opinion model """

import tensorflow as tf
from tensorflow import keras

tf.keras.backend.set_floatx('float32')

from pinn      import PhysicsInformedNN
from eq_no_phys import test
import matplotlib.pyplot as plt
import numpy as np


def cte_validation(self, X, t, Nt, Nx, u):
    # Definimos una función que el código después llama
    # El único parametro que le pasa código es el número de epoch
    # El resto lo definimos al generar la función
    def validation(ep):
        # Get prediction
        Y  = self.model(X)[0].numpy()

        u_p = Y[:,0]
        #.reshape((Nt,Nx))

        # True valu
        u_t  = u(t)

        # Error global
        err  = np.sqrt(np.mean((u_p-u_t)**2))/np.std(u_t)

        # Loss functions
        output_file = open(self.dest + 'validation.dat', 'a')
        print(ep, err,file=output_file)
        output_file.close()

    return validation

def gaussian( x , s):
    return 1./np.sqrt( 2. * np.pi * s**2 ) * np.exp( -x**2 / ( 2. * s**2 ) )

def solution(X):  
  sol = np.zeros(len(X))
  for i in range(len(X)):
    x = X[i,1]
    t_0 = X[i,0]
    lower = t_0 - 1
    uper = 1 - t_0    
    sol[i] = np.where((x<lower) | (x>uper),0,1) * 1/(2-2*t_0) 
  return sol.reshape((len(X),1))

def convolution(t):
  x_evaluate = np.array([(t[0],tt) for tt in np.linspace(-1.5,1.5,Nx)])          
  u_eval = solution(x_evaluate).reshape(-1)        
  gauss = gaussian(x_evaluate[:,1],0.02)  
  conv = np.convolve(u_eval,gauss,mode='same')  
  sol = ((conv/np.max(conv))*np.max(u_eval)).reshape((len(u_eval),1))
  t = np.delete(t,0)
  for t_0 in t:            
    x_evaluate = np.array([(t_0,tt) for tt in np.linspace(-1.5,1.5,Nx)])    
    u_eval = solution(x_evaluate).reshape(-1)        
    gauss = gaussian(x_evaluate[:,1],0.02)        
    conv = np.convolve(u_eval,gauss,mode='same')  
    sol = np.append(sol,((conv/np.max(conv))*np.max(u_eval)).reshape((len(u_eval),1)),axis=0)    
  return sol
    

#lr = keras.optimizers.schedules.ExponentialDecay(1e-3, 1000, 0.9)
lr = 1e-3
layers  = [2] + 3*[64] + [1]
PINN = PhysicsInformedNN(layers,
                         dest='./', #saque el /odir porque no hacia falta 
                         activation='elu',
                         optimizer=keras.optimizers.Adam(lr),
                         restore=True)
PINN.model.summary()
PINN.optimizer.learning_rate.assign(lr)

#True para entrenar la red, False para omitirlo
train = False

#Graficos 
sol_3D_show = False
model_3D_show = False
model_show = True # Solucion de la red en todo el espacio 
sol_show = True # Solucion real en todo el espacio
loss_val = False # Funcion de perdida + Validation
val = False # Validation sola
cond_in = True # Condicion inicial
x_0 = True # Sigo el punto x=0 para todo tiempo
rand_point = False #Miro un punto (X=0) a algun tiempo aleatorio 

Lx = 2
Nx = 200
Nt = 50

t = np.linspace(0,0.5,Nt)
x = np.linspace(-1.5,1.5,Nx)

T,X = np.meshgrid(t,x)  
X = np.hstack((np.sort(T.flatten()[:,None],axis=0),X.flatten(order='F')[:,None])) #Ordeno el vector como (t,x)

Y = convolution(t) #[u(t_0,x_0),u(t_1,x_1),...]


lambda_data = 1
lambda_phys = 0

alpha   = 0.0
tot_eps = 5000
eq_params = [Lx/Nx]
eq_params = [np.float32(p) for p in eq_params] #eq_params es el diferencial de x que paso para calcular la integral


# Se la agregamos a la clase
PINN.validation = cte_validation(PINN, X, t, Nt, Nx, convolution)

if train == True:
  PINN.train(X, Y, test,
             epochs=tot_eps,
             eq_params=eq_params,
             batch_size=Nt*Nx,
             lambda_data=lambda_data,   # Punto donde se enfuerza L_bc
             lambda_phys=lambda_phys,                 
             rnd_order_training=False,  # No arma batches al hacer
             alpha=alpha,
             verbose=True,
             valid_freq=100,             # Cada cuantas epochs usa la funcion validation
             timer=False)


fields = PINN.model(X)[0]

#Miro la condicion inicial
t_ini = 0.0
x_eval_1 = np.array([(t_ini,tt) for tt in np.linspace(-1.5,1.5,Nx)])
u_eval_1 = convolution([t_ini])
fields_eval_1 = PINN.model(x_eval_1)[0]

#Miro la solucion a t_fijo = t_0
t_fijo = 0.3
x_eval_2 = np.array([(t_fijo,tt) for tt in np.linspace(-1.5,1.5,Nx)])
u_eval_2 = convolution([t_fijo])
fields_eval_2 = PINN.model(x_eval_2)[0]

if sol_3D_show == True:
    fig = plt.figure(figsize = (10,10))
    ax = plt.axes(projection='3d')
    ax.scatter3D(X[:,0].flatten(), X[:,1].flatten(), u(X).flatten())
    ax.view_init(10,90)

if model_3D_show == True:  
    fig = plt.figure(figsize = (10,10))
    plt.title('Model')
    ax = plt.axes(projection='3d')
    ax.scatter3D(X[:,0].flatten(), X[:,1].flatten(), fields)
    ax.view_init(10,90)

if sol_show == True:
    solution = np.reshape(Y,(Nt,Nx))        
    solution = np.rot90(solution)
    plt.figure(figsize=(5,5))
    plt.imshow(solution, cmap = 'hot',extent=[0,np.max(t),-1,1],aspect=0.4)
    cax = plt.axes([0.85, 0.1, 0.075, 0.8])
    plt.colorbar(cax=cax)

if model_show == True:   
    model = np.reshape(fields,(Nt,Nx))      
    model = np.rot90(model)
    plt.figure(figsize=(5,5))
    plt.imshow(model, cmap = 'hot',extent=[0,np.max(t),-1,1],aspect=0.4)
    cax = plt.axes([0.85, 0.1, 0.1, 0.8])
    plt.colorbar(cax=cax)
    
if loss_val == True:
  plt.figure()
  out = np.loadtxt('output.dat', unpack=True)
  out_1 = np.loadtxt('validation.dat', unpack=True)
  plt.semilogy(out[0], out[1], label='Loss function')
  plt.semilogy(out_1[0], out_1[1], label='Validation')
  props = dict(boxstyle='round', facecolor='blue', alpha=0.1)
  textstr = '\n'.join((
    rf'(Nt,Nx)= ({Nt},{Nx})' ,
    r'Layers = 3*64' ,
    rf'Learning Rate = {lr} (fijo)' ,
    rf'Epochs = {tot_eps}'))
  plt.text(1500, 0.55, textstr, fontsize=10,
        verticalalignment='top', bbox=props)
  plt.title('Training loss/Validation')
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.legend()

if val == True:
    plt.figure()  
    out_1 = np.loadtxt('validation.dat', unpack=True)
    plt.semilogy(out_1[0], out_1[1], label='Validation')          
    plt.title('Validation')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    
if cond_in == True:
  plt.figure()
  plt.title('Condicion Inicial')
  plt.plot(x_eval_1[:,1],fields_eval_1,label = 'Red Neuronal')
  plt.plot(x_eval_1[:,1],u_eval_1,label = 'Solucion Real')
  plt.xlabel('X')
  plt.ylabel('u(X)')
  plt.legend()

if x_0 == True:
  plt.figure()
  plt.title(f'Solucion a t = {t_fijo}')
  props = dict(boxstyle='round', facecolor='blue', alpha=0.1)
  plt.plot(x_eval_2[:,1],fields_eval_2,label = 'Red Neuronal')
  plt.plot(x_eval_2[:,1],u_eval_2,label = 'Solucion Real')  
  plt.text(-0.85, 0.8, rf'$t_{0} = {t_fijo}$', fontsize=10,verticalalignment='top', bbox=props)
  plt.xlabel('X')
  plt.ylabel('$u(x,t = t_{0})$')
  plt.legend()

if rand_point == True:
  plt.figure()
  plt.legend()
  plt.scatter(x_0_eval[:,0],fields_eval,label = 'NN')
  plt.scatter(x_0_eval[:,0],u_0_eval,label = 'Solucion')
  plt.xlabel('t')
  plt.ylabel('u(x = 0,t)')
  plt.legend()


plt.show()